filename,dc.title,dc.creator,dc.description,dc.description,dcterms.abstract,dc.publisher,dc.contributor,dc.contributor,dc.contributor,dc.contributor,dc.date,dc.type,dc.type,dc.type,dc.type,dc.format,dc.format,dc.format,dc.format,dc.rights,dcterms.accessRights,dcterms.rightsHolder,dc.subject,dc.subject,dc.subject,dc.subject,dc.subject,dc.relation,dc.identifier,dc.coverage,physical location,dcterms.source,image specifications,dcterms.thesis.degree.name,dcterms.thesis.degree.discipline,dcterms.abstract,dcterms.abstract,dcterms.accessRights,dc.language
objects/Kodoku,Kodoku,"Jalbert, Patrick","EMAC Thesis project. Completed as part of the requirements for the B.S. in Electronic Media, Arts, and Communication (EMAC)",,"Kodoku is a simple story about the difficulty and dangers of standing up for one's self. It's premise as a piece of art, however, focuses on communicating human qualities through gesture. The goal was to bring human characteristics to inherently inhuman figures.","The School of Humanities, Arts and Social Sciences. (Troy NY: Rensselaer Polytechnic Institute, 2009)","Lawson, Shawn. Faculty advisor",,,,2009-05,Moving image,Still/Digital image,Sound,Text,Video/quicktime ,Image/jpeg2000,Application/pdf,Quicktime (.mov) video,"This licensed copy of an EMAC final thesis project is owned by Rensselaer Polytechnic Institute, Troy, NY. Copyright of the original work is retained by the author.",This work is licensed under the Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 United States License.,"Jalbert, Patrick",Robotics,Wings,Student projects,Animation,Computer animation,"Electronic Media, Arts, and Communication (EMAC) Final Projects Collection",,,,,,,,,,,
objects/147.tif,"Low, George M.",National Aeronautics and Space Administration,"George M. Low, Manager Apollo Spacecraft program, close up left profile.",,,National Aeronautics and Space Administration,National Aeronautics and Space Administration,,,,1969,Image,,,,"photograph, b/w, 8x10",,,,,,,"Low, George M.",,,,,George M. Low Papers,147,"Houston, TX","87-12, Box 135, Folder 4",87-12,"600 dpi, grayscale, Epson GT 10000+",,,,,,
objects/1869-11-20,"The Rensselaer Polytechnic v.1, no.5",,,,,"Troy, N.Y.: The Rensselaer Polytechnic",,,,,1869-11-20,Text,College student newspapers and periodicals,,,,,,,This material is in the public domain.,,,Rensselaer Polytechnic Institute -- Students -- Newspapers,College Students -- New York (State) -- Troy,,,,The Rensselaer Polytechnic Student Newspaper Collection,,,,Polytechnic microfilm reel #1,,,,,,,
objects/grebe,Vision based control of a mobile robot for driving applications,"Grebe, Gregory S.",May-17,School of Engineering,,"Rensselaer Polytechnic Institute, Troy, NY","Wen, John T.","Julius, Anak Agung","Fajen, Brett R.",,2017-05,Electronic thesis,,,,,,,,"This electronic version is a licensed copy owned by Rensselaer Polytechnic Institute, Troy, NY. Copyright of original work retained by author",Users may download and share copies with attribution in accordance with a Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 License. No commercial use or derivatives are permitted without the explicit approval of the author.,,,,,,,Rensselaer Theses and Dissertations Online Collection,,,,,,MS,"Dept. of Electrical, Computer, and Systems Engineering","Autonomous navigation of a shared roadway is a challenging task that requires an advanced model of the environment. Many autonomous vehicles currently achieve this using an expensive sensor suite based primarily on radar or LiDAR for navigation and control, while relegating vision to more contextual tasks. Nevertheless, vision can be extremely powerful and, as evidenced by human visual perception, provides useful information for the control of a vehicle. In this research, we examine the task of controlling vehicle headway using purely vision based controllers. The main idea is to design robot or vehicle controllers that mimic human visual perception models for the same task. Towards this end, we propose two controllers based on human visual perception models used in vehicle braking and vehicle following scenarios.","The second controller is based on using the visual angle of a lead vehicle to control and keep a constant following distance. The model is shown to be more numerically stable than a tau based approach, and can be easily tuned to match a desired second order system response. This algorithm is evaluated in both simulation and on a physical robot hardware implementation. Several driving scenarios are presented to showcase the algorithmï¾’s effectiveness, including videos of the results.",Users may download and share copies with attribution in accordance with a Creative Commons Attribution-Noncommercial-No Derivative Works 3.0 License. No commercial use or derivatives are permitted without the explicit approval of the author,ENG
